"""
rag.py â€” Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ñ‡ĞµÑ€ĞµĞ· Supabase + Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ñ‡ĞµÑ€ĞµĞ· Claude API.

ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° (Ğ´Ğ²ÑƒÑ…ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº):
  Ğ¨Ğ°Ğ³ 1: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿ĞµÑ€ĞµÑ‡Ğ½ĞµĞ¹ Ğ¢Ğ Ğ£ (ktru_perechen) â€” Ñ‚Ñ€Ğ¸ Ñ‚Ğ¸Ğ¿Ğ°:
          - upolnomoch_organ: ĞŸÑ€Ğ¸ĞºĞ°Ğ· ĞœĞ¤ â„–546 â€” ÑĞ¿Ğ¾ÑĞ¾Ğ± Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ ÑƒĞ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¼Ğ¾Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ€Ğ³Ğ°Ğ½
          - ooi: ĞŸÑ€Ğ¸ĞºĞ°Ğ· ĞœĞ¸Ğ½Ñ‚Ñ€ÑƒĞ´Ğ° â„–345 â€” Ğ·Ğ°ĞºÑƒĞ¿Ğ°ĞµÑ‚ÑÑ Ñƒ Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¹ Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¾Ğ²
          - msb: ĞŸÑ€Ğ¸ĞºĞ°Ğ· ĞœĞ¤ â„–677 â€” Ğ·Ğ°ĞºÑƒĞ¿Ğ°ĞµÑ‚ÑÑ Ñƒ ÑÑƒĞ±ÑŠĞµĞºÑ‚Ğ¾Ğ² ĞœĞ¡Ğ‘/ĞœĞ¡ĞŸ
  Ğ¨Ğ°Ğ³ 2: ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ chunks (PostgreSQL full-text) â€” Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğµ Ğ½Ğ¾Ñ€Ğ¼Ñ‹ Ğ·Ğ°ĞºĞ¾Ğ½Ğ°/Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ».
  Ğ˜Ñ‚Ğ¾Ğ³: Claude Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¾Ğ±Ğ° ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸ Ğ´Ğ°Ñ‘Ñ‚ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚.
"""

import os
import re
from anthropic import Anthropic
from supabase import create_client
from dotenv import load_dotenv

load_dotenv(override=True)

# â”€â”€â”€ ĞšĞ»Ğ¸ĞµĞ½Ñ‚Ñ‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

anthropic_client = Anthropic(api_key=os.environ["ANTHROPIC_API_KEY"])

supabase = create_client(
    os.environ["SUPABASE_URL"],
    os.environ["SUPABASE_KEY"],
)

# â”€â”€â”€ Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
_PROMPT_PATH = os.path.join(BASE_DIR, "prompts", "system_prompt.txt")
with open(_PROMPT_PATH, encoding="utf-8") as f:
    SYSTEM_PROMPT = f.read()

# â”€â”€â”€ ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¾ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğµ Ğ·Ğ°ĞºÑƒĞ¿ĞºĞ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Ğ•ÑĞ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ ÑÑ‚Ğ¸ ÑĞ»Ğ¾Ğ²Ğ° â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿ĞµÑ€ĞµÑ‡Ğ½Ğ¸ Ğ¢Ğ Ğ£ (Ğ²ÑĞµ Ñ‚Ñ€Ğ¸ Ñ‚Ğ¸Ğ¿Ğ°)
KTRU_TRIGGER_WORDS = [
    # ĞŸÑ€Ğ¸ĞºĞ°Ğ· â„–546 â€” ÑƒĞ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¼Ğ¾Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ€Ğ³Ğ°Ğ½
    "ÑĞ¿Ğ¾ÑĞ¾Ğ± Ğ·Ğ°ĞºÑƒĞ¿ĞºĞ¸", "ÑĞ¿Ğ¾ÑĞ¾Ğ± Ğ¾ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ»ĞµĞ½Ğ¸Ñ", "ĞºĞ°ĞºĞ¸Ğ¼ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ¾Ğ¼", "ĞºĞ°Ğº Ğ·Ğ°ĞºÑƒĞ¿Ğ°Ñ‚ÑŒ",
    "ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾-Ğ¼Ğ¾Ğ½Ñ‚Ğ°Ğ¶Ğ½Ñ‹Ğµ", "ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹", "ÑĞ¼Ñ€",
    "Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ½Ğ¾-ÑĞ¼ĞµÑ‚Ğ½Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ", "Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ½Ğ¾-ÑĞ¼ĞµÑ‚Ğ½Ğ¾Ğ¹",
    "Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¾-ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ", "Ñ‚ÑĞ¾",
    "ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¸Ğ·Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ²", "Ğ²Ğ½ĞµĞ²ĞµĞ´Ğ¾Ğ¼ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ°Ñ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¸Ğ·Ğ°",
    "Ğ¸Ğ½Ğ¶Ğ¸Ğ½Ğ¸Ñ€Ğ¸Ğ½Ğ³Ğ¾Ğ²Ñ‹Ğµ ÑƒÑĞ»ÑƒĞ³Ğ¸", "Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ½Ğ°Ğ´Ğ·Ğ¾Ñ€",
    "ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°Ğ¼Ğ¸",
    "Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğµ Ğ¾Ñ‚Ñ…Ğ¾Ğ´Ñ‹", "ÑƒÑ‚Ğ¸Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ñ…Ğ¾Ğ´Ğ¾Ğ²", "Ğ¿ĞµÑ€ĞµÑ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾Ñ‚Ñ…Ğ¾Ğ´Ğ¾Ğ²",
    "ÑƒÑĞ»ÑƒĞ³Ğ¸ ÑĞ²ÑĞ·Ğ¸",
    "Ğ¿ĞµÑ€ĞµÑ‡ĞµĞ½ÑŒ Ñ‚Ñ€Ñƒ", "Ğ¿ĞµÑ€ĞµÑ‡ĞµĞ½ÑŒ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²", "ÑƒĞ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¼Ğ¾Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ€Ğ³Ğ°Ğ½",
    "Ğ¿Ñ€Ğ¸ĞºĞ°Ğ· 546", "Ğ¿Ñ€Ğ¸ĞºĞ°Ğ· â„–546",
    "Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ğ¾Ğ²Ğ¾-Ğ±Ğ°Ğ»Ğ»ÑŒĞ½Ğ°Ñ",
    # ĞŸÑ€Ğ¸ĞºĞ°Ğ· â„–345 â€” ĞĞĞ˜ (Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¾Ğ²)
    "Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´", "Ğ¾Ğ¾Ğ¸", "Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¾Ğ²", "Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¾Ğ²",
    "Ğ»Ğ¸Ñ†Ğ° Ñ Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒÑ", "Ğ¿Ñ€Ğ¸ĞºĞ°Ğ· 345", "Ğ¿Ñ€Ğ¸ĞºĞ°Ğ· â„–345",
    "Ğ¿Ğ¾ÑÑ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ±ĞµĞ»ÑŒĞµ", "Ğ¾Ğ´ĞµÑĞ»Ğ¾", "Ğ¼Ğ°Ñ‚Ñ€Ğ°Ñ", "Ğ¼ĞµĞ±ĞµĞ»ÑŒ", "Ñ…Ğ°Ğ»Ğ°Ñ‚", "Ğ¿Ğ¸Ğ¶Ğ°Ğ¼",
    "ÑĞ¿ĞµÑ†Ğ¾Ğ´ĞµĞ¶Ğ´Ğ°", "Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ°Ñ Ğ¾Ğ´ĞµĞ¶Ğ´Ğ°", "ÑĞ°Ğ¶ĞµĞ½ĞµÑ†", "Ñ€Ğ°ÑÑĞ°Ğ´Ğ°", "ĞºĞ»Ğ¸Ğ½Ğ¸Ğ½Ğ³",
    "Ğ¿Ñ€Ğ°Ñ‡ĞµÑ‡Ğ½", "Ğ¿Ğ¾Ğ»Ğ¸Ğ³Ñ€Ğ°Ñ„",
    # ĞŸÑ€Ğ¸ĞºĞ°Ğ· â„–677 â€” ĞœĞ¡Ğ‘/ĞœĞ¡ĞŸ
    "Ğ¼Ğ°Ğ»Ñ‹Ğ¹ Ğ±Ğ¸Ğ·Ğ½ĞµÑ", "ÑÑ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ±Ğ¸Ğ·Ğ½ĞµÑ", "Ğ¼ÑĞ±", "Ğ¼ÑĞ¿",
    "Ğ¼Ğ°Ğ»Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ¾", "ÑÑ€ĞµĞ´Ğ½ĞµĞµ Ğ¿Ñ€ĞµĞ´Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ¾",
    "ÑÑƒĞ±ÑŠĞµĞºÑ‚ Ğ¼ÑĞ¿", "ÑÑƒĞ±ÑŠĞµĞºÑ‚ Ğ¼ÑĞ±", "Ğ¿Ñ€Ğ¸ĞºĞ°Ğ· 677", "Ğ¿Ñ€Ğ¸ĞºĞ°Ğ· â„–677",
    "50000 Ğ¼Ñ€Ğ¿", "50 000 Ğ¼Ñ€Ğ¿",
]

# â”€â”€â”€ ĞšĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚ÑƒÑÑ‰Ğ¸Ğµ Ğ½Ğ¾Ñ€Ğ¼Ñ‹: Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ¾Ğ² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚ÑƒÑÑ‰Ğ¸Ñ… Ğ½Ğ¾Ñ€Ğ¼ Ğ² Ğ·Ğ°ĞºĞ¾Ğ½Ğ¾Ğ´Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğµ (Ğ¤Ğ°Ğ·Ğ° 2 Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ñ)
CONFLICTING_NORMS = {
    "Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ_Ğº_Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ñƒ": {
        "keywords": ["ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚", "ÑĞºÑĞ¿ĞµÑ€Ñ‚", "Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»", "ĞºĞ°Ğ´Ñ€", "ÑĞ¾Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¸Ğº", "Ğ°Ñ‚Ñ‚ĞµÑÑ‚Ğ°Ñ†Ğ¸Ñ", "Ğ°ĞºĞºÑ€ĞµĞ´Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ñ", "ĞºĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ"],
        "positive_norms": [235, 241],           # ĞŸÑƒĞ½ĞºÑ‚Ñ‹ Ğ³Ğ´Ğµ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
        "conflicting_norms": [72],              # ĞŸÑƒĞ½ĞºÑ‚ 72 Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ğ°ĞµÑ‚ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ Ñ‚Ñ€ÑƒĞ´Ğ¾Ğ²Ñ‹Ğµ Ñ€ĞµÑÑƒÑ€ÑÑ‹
        "trigger_phrase": "Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğº ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚Ğ°Ğ¼ Ğ¸Ğ»Ğ¸ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ñƒ",
        "explanation": "ĞŸÑƒĞ½ĞºÑ‚ 72 Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ğ°ĞµÑ‚ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ñ… Ñ‚Ñ€ÑƒĞ´Ğ¾Ğ²Ñ‹Ñ… Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²",
        "conflict_chunk_ids": ["conflict_punkt72_personal_001_20260223_001", "conflict_punkt235_241_003_20260223_001"]
    },
    "ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ_Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ": {
        "keywords": ["ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ", "ÑÑ†Ğ¿", "Ñ†Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ñ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ", "ÑĞ¿", "Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚"],
        "positive_norms": [40],                 # ĞŸÑƒĞ½ĞºÑ‚ 40 Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ­Ğ¦ĞŸ
        "conflicting_grounds": ["Ğ½Ğ¾Ñ‚Ğ°Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ´Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ¸Ğµ", "Ğ·Ğ°Ğ²ĞµÑ‰Ğ°Ğ½Ğ¸Ğµ", "Ğ´Ğ°Ñ€ĞµĞ½Ğ¸Ğµ", "Ğ½ĞµĞ´Ğ²Ğ¸Ğ¶Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ"],  # Ğ˜ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ
        "trigger_phrase": "Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¸ Ğ¸ Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ",
        "explanation": "ĞŸÑƒĞ½ĞºÑ‚ 40 Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ­Ğ¦ĞŸ, Ğ½Ğ¾ ĞµÑÑ‚ÑŒ Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ² Ğ—Ğ°ĞºĞ¾Ğ½Ğµ Ğ¾Ğ± Ğ­Ğ¦ĞŸ",
        "conflict_chunk_ids": ["conflict_eps_punkt40_006"]
    },
    "Ğ¿Ñ€Ğ°Ğ²Ğ¾_Ğ½Ğ°_ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ğµ": {
        "keywords": ["ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ğµ", "Ğ´Ğ¾Ğ¿ÑƒÑĞº", "Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¸Ğµ", "Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ", "Ğ¾Ñ‚ĞºĞ°Ğ·", "Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ", "Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ", "Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğº ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸"],
        "positive_norms": [9],                  # Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ 9 Ğ—Ğ°ĞºĞ¾Ğ½Ğ° - Ğ¿Ñ€Ğ°Ğ²Ğ¾ Ğ½Ğ° ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ğµ
        "conflicting_norms": [40, 41, 42],      # ĞŸÑƒĞ½ĞºÑ‚Ñ‹ 40-42 Ğ´Ğ°ÑÑ‚ Ğ¸ÑÑ‡ĞµÑ€Ğ¿Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ñ‚ĞºĞ°Ğ·Ğ°
        "trigger_phrase": "ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ñ, Ğ´Ğ¾Ğ¿ÑƒÑĞºĞ° Ğ¸Ğ»Ğ¸ Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¸Ñ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ²",
        "explanation": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ 9 Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€Ğ°Ğ²Ğ¾ Ğ½Ğ° ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ğµ, Ğ½Ğ¾ Ğ¿ÑƒĞ½ĞºÑ‚Ñ‹ 40-42 Ğ´Ğ°ÑÑ‚ Ğ¸ÑÑ‡ĞµÑ€Ğ¿Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ñ‚ĞºĞ°Ğ·Ğ°",
        "conflict_chunk_ids": ["conflict_participation_rights_007", "conflict_exclusion_grounds_008", "conflict_discrimination_009"]
    },
    # SECONDARY CONFLICTS (Ğ’Ñ‚Ğ¾Ñ€Ğ¸Ñ‡Ğ½Ñ‹Ğµ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ñ‹ - Phase 4 Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ)
    "ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ_Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ_vs_Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ": {
        "keywords": ["ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ", "ÑÑ†Ğ¿", "Ğ¸Ğ½Ğ¾ÑÑ‚Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹", "Ğ½Ğ¾Ñ‚Ğ°Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ", "Ğ·Ğ°Ğ²ĞµÑ‰Ğ°Ğ½Ğ¸Ğµ", "Ğ´Ğ°Ñ€ĞµĞ½Ğ¸Ğµ", "Ğ¸Ğ½Ğ¾ÑÑ‚Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¹", "Ğ°Ğ¿Ğ¾ÑÑ‚Ğ¸Ğ»ÑŒ", "Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ", "Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ", "Ğ¸Ğ½Ğ¾ÑÑ‚Ñ€Ğ°Ğ½Ğ½Ñ‹Ğµ", "Ğ½ĞµĞ´Ğ²Ğ¸Ğ¶Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ", "Ğ¿Ñ€Ğ°Ğ²Ğ¾ ÑĞ¾Ğ±ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸"],
        "positive_norms": [40],
        "conflicting_norms": [16],  # Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ 16 Ğ—Ğ°ĞºĞ¾Ğ½Ğ° Ğ¾Ğ± Ğ­Ğ¦ĞŸ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ
        "trigger_phrase": "Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ· Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ­Ğ¦ĞŸ Ğ´Ğ»Ñ Ğ¸Ğ½Ğ¾ÑÑ‚Ñ€Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¾ÑĞ¾Ğ±Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²",
        "explanation": "ĞŸÑƒĞ½ĞºÑ‚ 40 Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ­Ğ¦ĞŸ, Ğ½Ğ¾ Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ 16 Ğ—Ğ°ĞºĞ¾Ğ½Ğ° Ğ¾Ğ± Ğ­Ğ¦ĞŸ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¸Ğ½Ğ¾ÑÑ‚Ñ€Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ², Ğ·Ğ°Ğ²ĞµÑ‰Ğ°Ğ½Ğ¸Ğ¹, Ğ´Ğ°Ñ€ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¾ Ğ½ĞµĞ´Ğ²Ğ¸Ğ¶Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸",
        "conflict_chunk_ids": ["conflict_eps_exceptions_010_20260224_001", "conflict_eps_exceptions_011_20260224_001"]
    },
    "Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ": {
        "keywords": ["Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ", "Ğ¼Ğ°Ğ»Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ğµ", "Ğ¾Ğ¿Ñ‹Ñ‚", "Ğ°ĞºĞºÑ€ĞµĞ´Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ñ", "Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸", "Ğ¼ĞµÑÑ‚Ğ¾ Ğ½Ğ°Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ", "Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ ÑĞ¾Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¸ĞºĞ¾Ğ²", "Ğ±Ğ°Ñ€ÑŒĞµÑ€", "Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğº ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸", "iso", "ÑĞµÑ€Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ", "Ğ¾Ğ¿Ñ‹Ñ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹"],
        "positive_norms": [9, 5],                # Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ 9 Ğ¸ ĞŸÑƒĞ½ĞºÑ‚ 5 Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ğ°ÑÑ‚ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ
        "conflicting_norms": [40, 41, 42],      # ĞŸÑƒĞ½ĞºÑ‚Ñ‹ 40-42 Ğ´Ğ°ÑÑ‚ Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ñ‚ĞºĞ°Ğ·Ğ°, Ğ½Ğ¾ Ğ¾Ğ½Ğ¸ Ğ½Ğµ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸
        "trigger_phrase": "Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµĞ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ±Ğ°Ñ€ÑŒĞµÑ€Ñ‹ Ğ´Ğ»Ñ ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ñ",
        "explanation": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ 9 Ğ¸ ĞŸÑƒĞ½ĞºÑ‚ 5 Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ğ°ÑÑ‚ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ğ»ÑĞ±Ñ‹Ğ¼ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ°Ğ¼, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ĞºĞ¾ÑĞ²ĞµĞ½Ğ½ÑƒÑ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Ñ‡Ñ€ĞµĞ·Ğ¼ĞµÑ€Ğ½Ñ‹Ğµ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ",
        "conflict_chunk_ids": ["conflict_discrimination_009", "conflict_discrimination_010_20260224_001", "conflict_discrimination_011_20260224_001"]
    }
}


def check_ktru_perechen(question: str) -> list[dict]:
    """
    Ğ¨Ğ°Ğ³ 1: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, ĞºĞ°ÑĞ°ĞµÑ‚ÑÑ Ğ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹ Ğ¸Ğ· ĞŸĞµÑ€ĞµÑ‡Ğ½Ñ Ğ¢Ğ Ğ£ (ĞŸÑ€Ğ¸ĞºĞ°Ğ· â„–546).
    Ğ•ÑĞ»Ğ¸ Ğ´Ğ° â€” Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ¸Ğ· Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ ktru_perechen.
    ĞŸĞ¾Ğ¸ÑĞº: Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾ Ğ¿Ğ¾Ğ»Ñ nazvanie (russian stemming).
    """
    q_lower = question.lower()

    # Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°: ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ğ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ°
    has_trigger = any(t in q_lower for t in KTRU_TRIGGER_WORDS)

    # Ğ’ÑĞµĞ³Ğ´Ğ° Ğ¸Ñ‰ĞµĞ¼ â€” ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ¸Ğ½ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ· ÑÑ„ĞµÑ€Ñ‹ Ğ·Ğ°ĞºÑƒĞ¿Ğ¾Ğº
    try:
        # Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ğ¼ tsquery Ğ¸Ğ· Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ² nazvanie
        words = re.sub(r"[^\w\s]", " ", q_lower).split()
        stopwords_ru = {
            "Ñ‡Ñ‚Ğ¾", "ĞºĞ°Ğº", "Ğ´Ğ»Ñ", "Ğ¿Ñ€Ğ¸", "Ğ¸Ğ»Ğ¸", "ÑÑ‚Ğ¾", "Ğ¸Ğ·", "Ğ¿Ğ¾", "Ğ²", "Ğ½Ğ°", "Ñ",
            "Ğ¸", "Ğ°", "Ğ½Ğ¾", "Ğ½Ğµ", "Ğ´Ğ°", "Ñ‚Ğ¾", "Ğ¶Ğµ", "Ğ»Ğ¸", "ĞµÑÑ‚ÑŒ", "ĞµÑĞ»Ğ¸", "ĞºĞ¾Ğ³Ğ´Ğ°",
            "Ğ³Ğ´Ğµ", "ĞºÑ‚Ğ¾", "Ñ‡ĞµĞ¼", "Ñ‚Ğ°Ğº", "Ğ²ÑĞµ", "Ğ¼Ğ¾Ğ¶Ğ½Ğ¾", "Ğ½ÑƒĞ¶Ğ½Ğ¾", "Ğ½Ğ°Ğ´Ğ¾",
            "ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹", "ĞºĞ°ĞºĞ¾Ğ¹", "ÑĞ²Ğ¾Ğ¹", "ÑÑ‚Ğ¾Ñ‚", "Ñ‚Ğ¾Ñ‚", "Ğ¾Ğ´Ğ¸Ğ½", "Ğ±Ñ‹Ñ‚ÑŒ", "Ğ¼Ğ¾Ğ¶ĞµÑ‚",
            "ĞºĞ°ĞºĞ¸Ğµ", "ĞºĞ°ĞºĞ¸Ğ¼", "ĞºĞ°ĞºĞ¾Ğ¹", "ĞºĞ°ĞºĞ¸Ğµ", "ĞºĞ°ĞºĞ¾Ğ¼",
        }
        keywords = [w for w in words if w not in stopwords_ru and len(w) > 3][:5]

        if not keywords:
            return []

        tsquery = " | ".join(keywords)  # OR-Ğ¿Ğ¾Ğ¸ÑĞº Ğ´Ğ»Ñ ÑˆĞ¸Ñ€Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ¾Ñ…Ğ²Ğ°Ñ‚Ğ°

        result = supabase.rpc(
            "search_ktru_perechen",
            {"query_text": tsquery}
        ).execute()

        if result.data:
            return result.data

        # Fallback: Ğ¿Ñ€ÑĞ¼Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ğ¾ ILIKE ĞµÑĞ»Ğ¸ RPC Ğ½Ğµ Ğ´Ğ°Ğ» Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
        if has_trigger:
            # Ğ‘ĞµÑ€Ñ‘Ğ¼ ÑĞ°Ğ¼Ğ¾Ğµ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğµ ĞºĞ»ÑÑ‡ĞµĞ²Ğ¾Ğµ ÑĞ»Ğ¾Ğ²Ğ¾ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
            best_kw = max(keywords, key=len) if keywords else None
            if best_kw and len(best_kw) > 4:
                result = supabase.table("ktru_perechen").select("*").ilike(
                    "nazvanie", f"%{best_kw}%"
                ).execute()
                return result.data or []

    except Exception:
        pass

    return []


def build_ktru_context(ktru_items: list[dict]) -> str:
    """
    Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑ€ĞµÑ‡Ğ½ĞµĞ¹ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Claude.
    Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ñƒ Ğ¿ĞµÑ€ĞµÑ‡Ğ½Ñ (upolnomoch_organ / ooi / msb).
    """
    if not ktru_items:
        return ""

    # ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ Ñ‚Ğ¸Ğ¿Ñƒ Ğ¿ĞµÑ€ĞµÑ‡Ğ½Ñ
    PERECHEN_META = {
        "upolnomoch_organ": {
            "title": "ĞŸĞ•Ğ Ğ•Ğ§Ğ•ĞĞ¬ Ğ¢Ğ Ğ£ â€” Ğ¡ĞŸĞĞ¡ĞĞ‘ Ğ—ĞĞšĞ£ĞŸĞšĞ˜ ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ¯Ğ•Ğ¢ Ğ£ĞŸĞĞ›ĞĞĞœĞĞ§Ğ•ĞĞĞ«Ğ™ ĞĞ Ğ“ĞĞ",
            "npa":   "ĞŸÑ€Ğ¸ĞºĞ°Ğ· ĞœĞ¤ Ğ Ğš Ğ¾Ñ‚ 15.08.2024 â„–546 (Ñ€ĞµĞ³. â„–34933)",
            "url":   "https://adilet.zan.kz/rus/docs/V2400034933",
        },
        "ooi": {
            "title": "ĞŸĞ•Ğ Ğ•Ğ§Ğ•ĞĞ¬ Ğ¢Ğ Ğ£ â€” Ğ—ĞĞšĞ£ĞŸĞĞ®Ğ¢Ğ¡Ğ¯ Ğ£ ĞĞ Ğ“ĞĞĞ˜Ğ—ĞĞ¦Ğ˜Ğ™ Ğ›Ğ˜Ğ¦ Ğ¡ Ğ˜ĞĞ’ĞĞ›Ğ˜Ğ”ĞĞĞ¡Ğ¢Ğ¬Ğ® (ĞĞĞ˜)",
            "npa":   "ĞŸÑ€Ğ¸ĞºĞ°Ğ· ĞœĞ¸Ğ½Ñ‚Ñ€ÑƒĞ´Ğ° Ğ¸ ÑĞ¾Ñ†Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹ Ğ Ğš Ğ¾Ñ‚ 03.09.2024 â„–345 (Ñ€ĞµĞ³. â„–35032)",
            "url":   "https://adilet.zan.kz/rus/docs/V2400035032",
        },
        "msb": {
            "title": "ĞŸĞ•Ğ Ğ•Ğ§Ğ•ĞĞ¬ Ğ¢Ğ Ğ£ â€” Ğ—ĞĞšĞ£ĞŸĞĞ®Ğ¢Ğ¡Ğ¯ Ğ£ Ğ¡Ğ£Ğ‘ĞªĞ•ĞšĞ¢ĞĞ’ ĞœĞ¡Ğ‘/ĞœĞ¡ĞŸ",
            "npa":   "ĞŸÑ€Ğ¸ĞºĞ°Ğ· ĞœĞ¤ Ğ Ğš Ğ¾Ñ‚ 08.10.2024 â„–677 (Ñ€ĞµĞ³. â„–35226)",
            "url":   "https://adilet.zan.kz/rus/docs/V2400035226",
        },
    }

    # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ñƒ
    from collections import defaultdict
    groups: dict[str, list[dict]] = defaultdict(list)
    for item in ktru_items:
        ptype = item.get("perechen_type", "upolnomoch_organ")
        groups[ptype].append(item)

    sections = []
    for ptype, items in groups.items():
        meta = PERECHEN_META.get(ptype, {
            "title": f"ĞŸĞ•Ğ Ğ•Ğ§Ğ•ĞĞ¬ ({ptype})",
            "npa": "", "url": "",
        })
        block = [
            f"## {meta['title']}",
            f"Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: {meta['npa']}",
            f"URL: {meta['url']}",
            "",
            "ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ¸Ğ· ĞŸĞµÑ€ĞµÑ‡Ğ½Ñ, ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ:",
        ]
        for item in items:
            razdel = item.get("razdel") or ""
            razdel_str = f" [{razdel}]" if razdel else ""
            codes = item.get("ektru_codes") or ""
            codes_str = f"\n   ĞšĞ¾Ğ´Ñ‹ Ğ•ĞšĞ¢Ğ Ğ£: {codes[:500]}" if codes else ""
            block.append(
                f"\n  {item['num']}. {item['nazvanie']}{razdel_str}\n"
                f"  Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ± Ğ·Ğ°ĞºÑƒĞ¿ĞºĞ¸: {item['sposob']}"
                f"{codes_str}"
            )
        sections.append("\n".join(block))

    return "# ĞŸĞ•Ğ Ğ•Ğ§ĞĞ˜ Ğ¢Ğ Ğ£ Ğ¡ ĞĞ¡ĞĞ‘Ğ«Ğœ ĞŸĞĞ Ğ¯Ğ”ĞšĞĞœ Ğ—ĞĞšĞ£ĞŸĞšĞ˜\n\n" + "\n\n".join(sections)


# â”€â”€â”€ Ğ”ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¿Ñ€Ğ¾ Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´ĞºĞ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Ğ¢Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ñ‹ Ğ´Ğ»Ñ goszakup.gov.kz
GOSZAKUP_TRIGGER_WORDS = [
    "goszakup", "Ğ³Ğ¾ÑĞ·Ğ°ĞºÑƒĞ¿", "Ğ¿Ğ¾Ñ€Ñ‚Ğ°Ğ» Ğ³Ğ¾ÑĞ·Ğ°ĞºÑƒĞ¿Ğ¾Ğº", "Ğ¿Ğ¾Ñ€Ñ‚Ğ°Ğ» Ğ·Ğ°ĞºÑƒĞ¿Ğ¾Ğº",
    "Ğ²ĞµĞ±-Ğ¿Ğ¾Ñ€Ñ‚Ğ°Ğ»", "Ğ²ĞµĞ±Ğ¿Ğ¾Ñ€Ñ‚Ğ°Ğ»", "ĞºĞ°Ğº Ğ²Ğ¾Ğ¹Ñ‚Ğ¸ Ğ½Ğ° Ğ¿Ğ¾Ñ€Ñ‚Ğ°Ğ»", "Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ ĞºĞ°Ğ±Ğ¸Ğ½ĞµÑ‚ Ğ·Ğ°ĞºĞ°Ğ·Ñ‡Ğ¸ĞºĞ°",
    "Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ ĞºĞ°Ğ±Ğ¸Ğ½ĞµÑ‚ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸ĞºĞ°", "ÑÑ†Ğ¿", "ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ñ†Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ñ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ",
    "ncalayer", "Ğ½ĞºĞ»ĞµĞµÑ€", "Ğ½ĞºĞ°Ğ»Ğ°ĞµÑ€", "ĞºĞ°Ğ·Ñ‚Ğ¾ĞºĞµĞ½", "kalkan",
    "ĞºĞ°Ğº Ğ·Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ", "Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Ğ¿Ğ¾Ñ€Ñ‚Ğ°Ğ»Ğµ", "Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ",
    "Ğ¿Ğ»Ğ°Ğ½ Ğ³Ğ¾ÑĞ·Ğ°ĞºÑƒĞ¿Ğ¾Ğº", "Ğ¿Ğ»Ğ°Ğ½ Ğ·Ğ°ĞºÑƒĞ¿Ğ¾Ğº", "ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ", "Ñ€Ğ°Ğ·Ğ¼ĞµÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ",
    "ĞºĞ¾Ğ½ĞºÑƒÑ€ÑĞ½Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ", "Ğ·Ğ°ÑĞ²ĞºĞ° Ğ½Ğ° ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ğµ", "Ñ†ĞµĞ½Ğ¾Ğ²Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ",
    "ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½ĞºÑƒÑ€Ñ", "Ğ°ÑƒĞºÑ†Ğ¸Ğ¾Ğ½", "Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ†ĞµĞ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹", "Ğ·Ñ†Ğ¿",
    "Ğ¸Ğ· Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°", "Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€ Ğ·Ğ°ĞºÑƒĞ¿ĞºĞ¸", "Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»", "Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ Ğ¾ Ğ·Ğ°ĞºÑƒĞ¿ĞºĞµ",
    "Ğ½ĞµÑ‚ Ğ·Ğ°ÑĞ²Ğ¾Ğº", "Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°Ğ½ Ğ½ĞµÑĞ¾ÑÑ‚Ğ¾ÑĞ²ÑˆĞ¸Ğ¼ÑÑ", "Ğ¶Ğ°Ğ»Ğ¾Ğ±Ğ°", "Ğ°Ğ¿ĞµĞ»Ğ»ÑÑ†Ğ¸Ñ",
    "Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¿Ğ¾Ñ€Ñ‚Ğ°Ğ»Ñƒ", "ĞºĞ°Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ñ Ğ¿Ğ¾Ñ€Ñ‚Ğ°Ğ»Ğ¾Ğ¼",
]

# Ğ¢Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ñ‹ Ğ´Ğ»Ñ omarket.kz
OMARKET_TRIGGER_WORDS = [
    "omarket", "Ğ¾Ğ¼Ğ°Ñ€ĞºĞµÑ‚", "ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½", "ÑĞ».Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½",
    "Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚-Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½ Ğ·Ğ°ĞºÑƒĞ¿Ğ¾Ğº", "Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½ Ğ³Ğ¾ÑĞ·Ğ°ĞºÑƒĞ¿Ğ¾Ğº",
    "ĞºĞ°Ğº ĞºÑƒĞ¿Ğ¸Ñ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½", "Ğ·Ğ°ÑĞ²ĞºĞ° Ğ² Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½", "Ğ¾Ñ„ĞµÑ€Ñ‚Ğ°",
    "ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²", "ĞºĞ¾Ñ€Ğ·Ğ¸Ğ½Ğ° Ğ·Ğ°ĞºÑƒĞ¿Ğ¾Ğº", "Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ² ĞºĞ¾Ñ€Ğ·Ğ¸Ğ½Ñƒ",
    "ĞºĞ°Ñ€Ñ‚Ğ¾Ñ‡ĞºĞ° Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°", "Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº Ğ² Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½Ğµ", "Ğ¿Ğ¾Ğ´Ğ°Ñ‚ÑŒ Ğ¾Ñ„ĞµÑ€Ñ‚Ñƒ",
    "Ñ€Ğ°Ğ·Ğ¼ĞµÑÑ‚Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾Ğ²Ğ°Ñ€", "Ğ¿Ñ€Ğ°Ğ¹Ñ Ğ»Ğ¸ÑÑ‚", "Ğ¿Ñ€Ğ°Ğ¹Ñ-Ğ»Ğ¸ÑÑ‚ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸ĞºĞ°",
    "Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ·Ğ°ÑĞ²ĞºĞ¸", "Ğ¾Ñ‚ĞºĞ°Ğ· Ğ² Ğ·Ğ°ÑĞ²ĞºĞµ", "ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ·Ğ°ÑĞ²ĞºĞ¸",
    "ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½ Ğ·Ğ°ĞºÑƒĞ¿Ğ¾Ğº",
]


def detect_platform(question: str) -> str | None:
    """
    ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚, Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ÑÑ Ğ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğº ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´ĞºĞµ.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ 'goszakup', 'omarket' Ğ¸Ğ»Ğ¸ None (Ğ½ĞµÑ‚ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ¸ Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´ĞºĞ¸).
    ĞŸÑ€ÑĞ¼Ğ¾Ğµ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´ĞºĞ¸ Ğ¸Ğ¼ĞµĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ Ğ½Ğ°Ğ´ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğ¼Ğ¸ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ğ°Ğ¼Ğ¸.
    """
    q = question.lower()

    # ĞŸÑ€ÑĞ¼Ñ‹Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´Ğ¾Ğº â€” Ğ²Ñ‹ÑÑˆĞ¸Ğ¹ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚
    has_omarket   = any(t in q for t in ["omarket", "Ğ¾Ğ¼Ğ°Ñ€ĞºĞµÑ‚"])
    has_goszakup  = any(t in q for t in ["goszakup", "Ğ³Ğ¾ÑĞ·Ğ°ĞºÑƒĞ¿"])

    if has_omarket and not has_goszakup:
        return "omarket"
    if has_goszakup and not has_omarket:
        return "goszakup"

    # ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğµ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ñ‹ (Ğ±ĞµĞ· ÑƒÑ‡Ñ‘Ñ‚Ğ° Ğ¿Ñ€ÑĞ¼Ñ‹Ñ… Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğ¹)
    gz_score = sum(1 for t in GOSZAKUP_TRIGGER_WORDS
                   if t not in ("goszakup", "Ğ³Ğ¾ÑĞ·Ğ°ĞºÑƒĞ¿") and t in q)
    om_score  = sum(1 for t in OMARKET_TRIGGER_WORDS
                    if t not in ("omarket", "Ğ¾Ğ¼Ğ°Ñ€ĞºĞµÑ‚") and t in q)

    if gz_score == 0 and om_score == 0:
        return None
    return "goszakup" if gz_score >= om_score else "omarket"


# â”€â”€â”€ Ğ”ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¿Ñ€Ğ¾ ĞĞ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ´ĞµĞºÑ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Ğ¢Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ğ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ² ĞĞ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğ¼ ĞºĞ¾Ğ´ĞµĞºÑĞµ (tax)
TAX_CODE_TRIGGERS = [
    # ĞĞ”Ğ¡
    "ĞĞ”Ğ¡", "Ğ½Ğ´Ñ", "Ğ½Ğ°Ğ»Ğ¾Ğ³ Ğ½Ğ° Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ½ÑƒÑ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ", "Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ğ°Ñ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ",
    "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ğ±Ğ°Ğ·Ğ°", "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ğ°Ğ²ĞºĞ°", "ÑÑ‡ĞµÑ‚ Ñ„Ğ°ĞºÑ‚ÑƒÑ€Ğ°", "ÑÑ‡ĞµÑ‚-Ñ„Ğ°ĞºÑ‚ÑƒÑ€Ğ°",
    "ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ ÑÑ‡ĞµÑ‚", "Ğ°Ğ²Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ»Ğ°Ñ‚ĞµĞ¶", "Ğ°Ğ²Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ğ¹ ÑÑ‡ĞµÑ‚",
    # ĞĞ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğµ Ğ»ÑŒĞ³Ğ¾Ñ‚Ñ‹
    "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğµ Ğ»ÑŒĞ³Ğ¾Ñ‚Ñ‹", "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ğ»ÑŒĞ³Ğ¾Ñ‚Ğ°", "Ğ»ÑŒĞ³Ğ¾Ñ‚Ğ° Ğ¿Ğ¾ ĞĞ”Ğ¡",
    "ÑƒĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ¾Ğ±Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ", "ÑƒÑĞ½", "Ğ»ÑŒĞ³Ğ¾Ñ‚Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼",
    # ĞĞ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğµ Ñ€ĞµĞ·Ğ¸Ğ´ĞµĞ½Ñ‚Ñ‹
    "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ñ€ĞµĞ·Ğ¸Ğ´ĞµĞ½Ñ‚", "Ğ½ĞµÑ€ĞµĞ·Ğ¸Ğ´ĞµĞ½Ñ‚", "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ",
    # Ğ£Ñ‡ĞµÑ‚ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ¾Ğ²/Ñ€Ğ°ÑÑ…Ğ¾Ğ´Ğ¾Ğ²
    "Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ°", "Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°Ğ½Ğ¸Ğµ Ñ€Ğ°ÑÑ…Ğ¾Ğ´Ğ¾Ğ²", "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ ÑƒÑ‡ĞµÑ‚",
    "Ğ²Ñ‹Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼Ñ‹Ğµ Ñ€Ğ°ÑÑ…Ğ¾Ğ´Ñ‹", "ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ",
    # ĞĞ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ
    "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°", "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğµ Ğ¾Ñ€Ğ³Ğ°Ğ½Ñ‹", "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ğ·Ğ°Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ",
    "Ğ¿ĞµĞ½Ğ¸ Ğ¿Ğ¾ Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ°Ğ¼", "ÑˆÑ‚Ñ€Ğ°Ñ„Ğ½Ñ‹Ğµ ÑĞ°Ğ½ĞºÑ†Ğ¸Ğ¸", "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¾Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ",
    # Ğ‘ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€ÑĞºĞ¸Ğ¹ ÑƒÑ‡ĞµÑ‚
    "Ğ±ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€ÑĞºĞ¸Ğ¹ ÑƒÑ‡ĞµÑ‚", "Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´ĞºĞ°", "ÑÑ‡ĞµÑ‚", "Ğ±Ğ°Ğ»Ğ°Ğ½Ñ", "Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ",
    "Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ğ°Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ", "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ğ´ĞµĞºĞ»Ğ°Ñ€Ğ°Ñ†Ğ¸Ñ",
    # ĞĞ±Ñ‰Ğ¸Ğµ
    "Ğ½Ğ°Ğ»Ğ¾Ğ³", "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸", "Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹", "Ğ±ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€Ğ¸Ñ", "Ğ°ĞºĞºĞ°ÑƒĞ½Ñ‚Ğ¸Ğ½Ğ³",
]


def needs_tax_code(question: str) -> bool:
    """
    ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ»Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸ÑĞºĞ°Ñ‚ÑŒ Ğ½Ğ¾Ñ€Ğ¼Ñ‹ ĞĞ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ´ĞµĞºÑĞ°.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ True ĞµÑĞ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ ĞºĞ°ÑĞ°ĞµÑ‚ÑÑ ĞĞ”Ğ¡, Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ñ… Ğ»ÑŒĞ³Ğ¾Ñ‚, ÑƒÑ‡ĞµÑ‚Ğ° Ğ¸ Ñ‚.Ğ¿.
    """
    q = question.lower()
    return any(t in q for t in TAX_CODE_TRIGGERS)


# â”€â”€â”€ Ğ”ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¿Ñ€Ğ¾ Ğ“Ñ€Ğ°Ğ¶Ğ´Ğ°Ğ½ÑĞºĞ¸Ğ¹ ĞºĞ¾Ğ´ĞµĞºÑ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Ğ¢Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ğ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ² Ğ“Ğš Ğ Ğš (civil_code)
CIVIL_CODE_TRIGGERS = [
    # Ğ”Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ğ¾Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¾
    "Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€", "Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°", "Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğµ", "Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ¼", "Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ñ‹Ñ…",
    "Ğ¾Ñ„ĞµÑ€Ñ‚Ğ°", "Ğ¾Ñ„ĞµÑ€Ñ‚Ñƒ", "Ğ¾Ñ„ĞµÑ€Ñ‚Ñ‹", "Ğ°ĞºÑ†ĞµĞ¿Ñ‚", "Ğ°ĞºÑ†ĞµĞ¿Ñ‚Ğ°",
    "Ğ·Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°", "Ñ€Ğ°ÑÑ‚Ğ¾Ñ€Ğ¶ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°", "Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°",
    # ĞĞ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ°
    "Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ¾", "Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ°", "Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²", "Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ°Ñ…",
    "Ğ¸ÑĞ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ°", "Ğ¿Ñ€ĞµĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ°",
    # ĞÑ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ
    "Ğ½ĞµÑƒÑÑ‚Ğ¾Ğ¹ĞºĞ°", "Ğ½ĞµÑƒÑÑ‚Ğ¾Ğ¹ĞºĞ¸", "Ğ½ĞµÑƒÑÑ‚Ğ¾Ğ¹ĞºÑƒ", "ÑˆÑ‚Ñ€Ğ°Ñ„", "ÑˆÑ‚Ñ€Ğ°Ñ„Ğ°", "ÑˆÑ‚Ñ€Ğ°Ñ„Ğ½Ñ‹Ğµ",
    "Ğ¿ĞµĞ½Ñ", "Ğ¿ĞµĞ½Ğ¸", "ÑƒĞ±Ñ‹Ñ‚ĞºĞ¸", "ÑƒĞ±Ñ‹Ñ‚ĞºĞ¾Ğ²", "Ğ²Ğ¾Ğ·Ğ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ ÑƒĞ±Ñ‹Ñ‚ĞºĞ¾Ğ²",
    "ÑƒÑ‰ĞµÑ€Ğ±", "ÑƒÑ‰ĞµÑ€Ğ±Ğ°", "Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑƒÑ‰ĞµÑ€Ğ±", "ÑƒĞ¿ÑƒÑ‰ĞµĞ½Ğ½Ğ°Ñ Ğ²Ñ‹Ğ³Ğ¾Ğ´Ğ°",
    "Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½", "Ğ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ°Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ",
    # ĞšÑƒĞ¿Ğ»Ñ-Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ° Ğ¸ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ°
    "Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ° Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°", "Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¸", "ĞºÑƒĞ¿Ğ»Ñ-Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ°",
    "Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ÑŒ", "Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ²ĞµÑ†", "Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº Ğ¾Ğ±ÑĞ·Ğ°Ğ½",
    # Ğ“Ñ€Ğ°Ğ¶Ğ´Ğ°Ğ½ÑĞºĞ¸Ğ¹ ĞºĞ¾Ğ´ĞµĞºÑ
    "Ğ³Ñ€Ğ°Ğ¶Ğ´Ğ°Ğ½ÑĞºĞ¸Ğ¹ ĞºĞ¾Ğ´ĞµĞºÑ", "Ğ³Ğº Ñ€Ğº", "ÑÑ‚. Ğ³Ğº", "ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ³Ğº",
    "Ğ½Ğ¾Ñ€Ğ¼Ñ‹ Ğ³Ğº", "Ğ¿Ğ¾ Ğ³Ğº", "ÑĞ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ Ğ³Ğº",
    # Ğ¡Ğ´ĞµĞ»ĞºĞ¸ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°
    "Ğ½ĞµĞ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ ÑĞ´ĞµĞ»ĞºĞ°", "Ğ½Ğ¸Ñ‡Ñ‚Ğ¾Ğ¶Ğ½Ğ°Ñ ÑĞ´ĞµĞ»ĞºĞ°",
    "Ğ¿Ğ¸ÑÑŒĞ¼ĞµĞ½Ğ½Ğ°Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°", "ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ° Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°",
    # Ğ˜ÑĞº Ğ¸ Ğ¿Ñ€ĞµÑ‚ĞµĞ½Ğ·Ğ¸Ñ
    "Ğ¸ÑĞº", "Ğ¿Ñ€ĞµÑ‚ĞµĞ½Ğ·Ğ¸Ñ", "Ğ¸ÑĞºĞ¾Ğ²Ğ°Ñ Ğ´Ğ°Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ", "ÑÑ€Ğ¾Ğº Ğ´Ğ°Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸",
    # ĞšĞ°Ğ·Ğ°Ñ…ÑĞºĞ¸Ğµ ÑĞºĞ²Ğ¸Ğ²Ğ°Ğ»ĞµĞ½Ñ‚Ñ‹
    "ÑˆĞ°Ñ€Ñ‚", "ÑˆĞ°Ñ€Ñ‚Ñ‚Ñ‹Ò£", "ÑˆĞ°Ñ€Ñ‚Ñ‚Ñ‹", "Ó©Ñ‚ĞµĞ¼Ğ°Ò›Ñ‹", "Ğ°Ğ¹Ñ‹Ğ¿Ğ¿Ò±Ğ»",
]


def needs_civil_code(question: str) -> bool:
    """
    ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ»Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸ÑĞºĞ°Ñ‚ÑŒ Ğ½Ğ¾Ñ€Ğ¼Ñ‹ Ğ“Ğš Ğ Ğš.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ True ĞµÑĞ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ ĞºĞ°ÑĞ°ĞµÑ‚ÑÑ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ°Ğ²Ğ°, Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ‚.Ğ¿.
    """
    q = question.lower()
    return any(t in q for t in CIVIL_CODE_TRIGGERS)


# â”€â”€â”€ Ğ¡Ñ‚Ğ¾Ğ¿-ÑĞ»Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

STOPWORDS = {
    "Ñ‡Ñ‚Ğ¾", "ĞºĞ°Ğº", "Ğ´Ğ»Ñ", "Ğ¿Ñ€Ğ¸", "Ğ¸Ğ»Ğ¸", "ÑÑ‚Ğ¾", "Ğ¸Ğ·", "Ğ¿Ğ¾", "Ğ²", "Ğ½Ğ°", "Ñ",
    "Ğ¸", "Ğ°", "Ğ½Ğ¾", "Ğ½Ğµ", "Ğ´Ğ°", "Ñ‚Ğ¾", "Ğ¶Ğµ", "Ğ»Ğ¸", "ĞµÑÑ‚ÑŒ", "ĞµÑĞ»Ğ¸", "ĞºĞ¾Ğ³Ğ´Ğ°",
    "Ğ³Ğ´Ğµ", "ĞºÑ‚Ğ¾", "Ñ‡ĞµĞ¼", "Ñ‚Ğ°Ğº", "Ğ²ÑĞµ", "Ğ¼Ğ¾Ğ¶Ğ½Ğ¾", "Ğ½ÑƒĞ¶Ğ½Ğ¾", "Ğ½Ğ°Ğ´Ğ¾", "Ñ‚Ğ°ĞºĞ¾Ğ¹",
    "ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹", "ĞºĞ°ĞºĞ¾Ğ¹", "ÑĞ²Ğ¾Ğ¹", "ÑÑ‚Ğ¾Ñ‚", "Ñ‚Ğ¾Ñ‚", "Ğ¾Ğ´Ğ¸Ğ½", "Ğ±Ñ‹Ñ‚ÑŒ", "Ğ¼Ğ¾Ğ¶ĞµÑ‚",
}


def build_tsquery(question: str) -> str:
    """
    ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ² PostgreSQL tsquery.
    ĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: 'Ğ´ĞµĞ¼Ğ¿Ğ¸Ğ½Ğ³Ğ¾Ğ²Ğ°Ñ Ñ†ĞµĞ½Ğ° Ğ¼ĞµÑ€Ñ‹' â†’ 'Ğ´ĞµĞ¼Ğ¿Ğ¸Ğ½Ğ³Ğ¾Ğ²Ğ°Ñ & Ñ†ĞµĞ½Ğ° & Ğ¼ĞµÑ€Ñ‹'
    Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ·Ğ°Ğ¼ĞµĞ½Ñƒ Ğ°Ğ±Ğ±Ñ€ĞµĞ²Ğ¸Ğ°Ñ‚ÑƒÑ€ Ğ¸ ÑĞ¸Ğ½Ğ¾Ğ½Ğ¸Ğ¼Ğ¾Ğ² Ğ´Ğ»Ñ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°.
    """
    # Ğ—Ğ°Ğ¼ĞµĞ½Ğ° Ğ°Ğ±Ğ±Ñ€ĞµĞ²Ğ¸Ğ°Ñ‚ÑƒÑ€ Ğ¸ ÑĞ¸Ğ½Ğ¾Ğ½Ğ¸Ğ¼Ğ¾Ğ² Ğ½Ğ° ÑĞ»Ğ¾Ğ²Ğ° Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ² Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²
    SYNONYMS = {
        "ĞºÑ‚Ğ¿":  "Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ĞµĞ¹",
        "Ğ´Ğ²Ñ†":  "Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ÑÑ‚Ñ€Ğ°Ğ½Ğ¾Ğ²Ğ¾Ğ¹",
        "Ğ¾Ğ¾Ğ¾":  "Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ",
        "Ğ¼ÑĞ±":  "Ğ¿Ñ€ĞµĞ´Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ¾",
        "Ğ¼ÑĞ¿":  "Ğ¿Ñ€ĞµĞ´Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ¾",
        "Ğ¾Ğ¾Ğ¸":  "Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒÑ",
        "ÑĞ¼Ñ€":  "ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾-Ğ¼Ğ¾Ğ½Ñ‚Ğ°Ğ¶Ğ½Ñ‹Ğµ",
        "Ñ‚Ñ€Ñƒ":  "Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²",
        "Ñ„Ğ¾Ñ‚":  "Ñ‚Ñ€ÑƒĞ´Ğ°",
        "Ğ½Ğ¿Ğ°":  "Ğ½Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹",
        "ĞºĞ°Ğ·Ğ°Ñ…ÑÑ‚Ğ°Ğ½ÑĞºĞ¾Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ": "Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ĞµĞ¹",
        "ĞºĞ°Ğ·Ğ°Ñ…ÑÑ‚Ğ°Ğ½ÑĞºĞ¾Ğ³Ğ¾ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ñ": "Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ĞµĞ¹",
        "ĞºĞ°Ğ·Ğ°Ñ…ÑÑ‚Ğ°Ğ½ÑĞºĞ¾Ğ¼ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğ¸": "Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ĞµĞ¹",
    }
    q = question.lower()
    # ĞœĞ½Ğ¾Ğ³Ğ¾ÑĞ»Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¼ĞµĞ½Ñ‹ ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ°
    for phrase, replacement in SYNONYMS.items():
        if " " in phrase:
            q = q.replace(phrase, replacement)
    words = re.sub(r"[^\w\s]", " ", q).split()
    expanded = []
    for w in words:
        if w in SYNONYMS and " " not in SYNONYMS[w]:
            expanded.append(SYNONYMS[w])
        else:
            expanded.append(w)
    keywords = [w for w in expanded if w not in STOPWORDS and len(w) > 2]
    if not keywords:
        keywords = question.lower().split()[:3]
    return " & ".join(keywords[:6])


# â”€â”€â”€ ĞŸĞ¾Ğ¸ÑĞº Ğ² Supabase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def search_supabase(question: str, top_n: int = 6,
                    platform: str | None = None) -> list[dict]:
    """
    Ğ˜Ñ‰ĞµÑ‚ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğµ Ñ‡Ğ°Ğ½ĞºĞ¸ Ğ² Supabase Ñ‡ĞµÑ€ĞµĞ· PostgreSQL full-text search.
    Ğ•ÑĞ»Ğ¸ platform Ğ·Ğ°Ğ´Ğ°Ğ½ ('goszakup'/'omarket'/'law') â€” Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµÑ‚ Ğ¿Ğ¾ Ğ½ĞµĞ¼Ñƒ.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ‡Ğ°Ğ½ĞºĞ¾Ğ² Ğ¾Ñ‚ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸.
    """
    tsquery = build_tsquery(question)
    params = {"query_text": tsquery, "match_count": top_n}
    if platform:
        params["platform_filter"] = platform

    try:
        result = supabase.rpc("search_chunks", params).execute()
        if result.data:
            return result.data
    except Exception:
        pass

    # Fallback: OR Ğ²Ğ¼ĞµÑÑ‚Ğ¾ AND
    try:
        params_or = dict(params)
        params_or["query_text"] = " | ".join(tsquery.split(" & "))
        result = supabase.rpc("search_chunks", params_or).execute()
        if result.data:
            return result.data
    except Exception:
        pass

    return []


def detect_conflicting_norms(question: str, found_chunks: list[dict]) -> dict | None:
    """
    ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ²Ğ°ĞµÑ‚ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚ÑƒÑÑ‰Ğ¸Ğµ Ğ½Ğ¾Ñ€Ğ¼Ñ‹ Ğ¿Ñ€Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğµ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğµ Ğ¸Ğ»Ğ¸ None ĞµÑĞ»Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ° Ğ½ĞµÑ‚.

    Ğ¤Ğ°Ğ·Ğ° 2 (Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ): ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ 3 Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ñ… Ñ‚Ğ¸Ğ¿Ğ° ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ¾Ğ²:
    1. Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ_Ğº_Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ñƒ (ĞŸÑƒĞ½ĞºÑ‚ 72 vs ĞŸÑƒĞ½ĞºÑ‚Ñ‹ 235-241)
    2. ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ_Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ (ĞŸÑƒĞ½ĞºÑ‚ 40 vs Ğ˜ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ)
    3. Ğ¿Ñ€Ğ°Ğ²Ğ¾_Ğ½Ğ°_ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ğµ (Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ 9 vs ĞŸÑƒĞ½ĞºÑ‚Ñ‹ 40-42, Ğ”Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ)
    """
    q_lower = question.lower()

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞºĞ°Ğ¶Ğ´ÑƒÑ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ¾Ğ²
    for conflict_type, conflict_data in CONFLICTING_NORMS.items():
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ğ½Ñ‹Ñ… ÑĞ»Ğ¾Ğ²
        has_trigger = any(keyword in q_lower for keyword in conflict_data.get("keywords", []))

        if not has_trigger:
            continue

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ»Ğ¸ Ğ½Ğ¾Ñ€Ğ¼Ñ‹ Ğ¸Ğ· positive_norms Ğ¸Ğ»Ğ¸ conflicting_norms
        positive_found = any(
            str(norm) in str(chunk.get("chapter", "")) or str(norm) in str(chunk.get("article_title", ""))
            for chunk in found_chunks
            for norm in conflict_data.get("positive_norms", [])
        )

        conflicting_found = any(
            str(norm) in str(chunk.get("chapter", "")) or str(norm) in str(chunk.get("article_title", ""))
            for chunk in found_chunks
            for norm in conflict_data.get("conflicting_norms", [])
        )

        # Ğ”Ğ»Ñ Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ñ‡Ğ½Ñ‹Ñ… ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ¾Ğ²: ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€ Ğ¸ predefined chunks - Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¸Ñ… Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ
        # Ğ”Ğ»Ñ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ñ… ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ¾Ğ²: Ñ‚Ñ€ĞµĞ±ÑƒĞµĞ¼ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ½Ğ¾Ñ€Ğ¼Ñƒ Ğ² chunks
        has_predefined_chunks = bool(conflict_data.get("conflict_chunk_ids", []))
        is_secondary = conflict_type in ["ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ_Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ_vs_Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ", "Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ"]

        if (positive_found or conflicting_found) or (is_secondary and has_trigger and has_predefined_chunks):
            conflicting_chunks = []

            # Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ predefined chunk IDs (Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚)
            conflict_chunk_ids = conflict_data.get("conflict_chunk_ids", [])
            if conflict_chunk_ids:
                try:
                    for chunk_id in conflict_chunk_ids:
                        result = supabase.table("chunks").select("*").eq("id", chunk_id).execute()
                        if result.data:
                            conflicting_chunks.extend(result.data)
                except Exception:
                    pass

            # Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2: Ğ•ÑĞ»Ğ¸ predefined chunks Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ - Ğ¸Ñ‰ĞµĞ¼ Ğ¿Ğ¾ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ¼
            if not conflicting_chunks:
                for norm in conflict_data.get("conflicting_norms", []):
                    results = search_supabase(f"Ğ¿ÑƒĞ½ĞºÑ‚ {norm}", top_n=2, platform="law")
                    if results:
                        conflicting_chunks.extend(results)

            # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ ĞµÑĞ»Ğ¸ Ğ½Ğ°ÑˆĞ»Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚
            if conflicting_chunks:
                return {
                    "type": conflict_type,
                    "positive_norms": conflict_data.get("positive_norms", []),
                    "conflicting_norms": conflict_data.get("conflicting_norms", []),
                    "conflicting_chunks": conflicting_chunks,
                    "explanation": conflict_data.get("explanation", "Ğ•ÑÑ‚ÑŒ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ¼Ğ¸"),
                    "trigger_phrase": conflict_data.get("trigger_phrase", ""),
                }

    return None


def build_context(chunks: list[dict]) -> str:
    """Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸Ğ· Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²."""
    parts = []
    for chunk in chunks:
        header = chunk.get("article_title") or chunk.get("chapter") or ""
        platform = chunk.get("source_platform", "")
        platform_label = f" [{platform.upper()}]" if platform and platform != "law" else ""
        parts.append(
            f"[{chunk['id']}] {chunk['document_short']}{platform_label} | {header}\n"
            f"Ğ¡ÑÑ‹Ğ»ĞºĞ°: {chunk['official_url']}\n"
            f"{chunk['text']}\n"
            f"{'=' * 60}"
        )
    return "\n".join(parts)


# â”€â”€â”€ ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def answer_question(question: str, conversation_history: list) -> tuple[str, int, bool]:
    """
    ĞŸÑÑ‚Ğ¸ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº:
      Ğ¨Ğ°Ğ³ 1 â€” ĞŸĞµÑ€ĞµÑ‡Ğ½Ğ¸ Ğ¢Ğ Ğ£ (ĞšĞ¢Ğ Ğ£, ĞĞĞ˜, ĞœĞ¡Ğ‘)
      Ğ¨Ğ°Ğ³ 2 â€” Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´Ğ¾Ğº (goszakup / omarket) ĞµÑĞ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ñ€Ğ¾ Ğ½Ğ¸Ñ…
      Ğ¨Ğ°Ğ³ 3 â€” ĞĞ¾Ñ€Ğ¼Ñ‹ Ğ—Ğ°ĞºĞ¾Ğ½Ğ° Ğ¸ ĞŸÑ€Ğ°Ğ²Ğ¸Ğ» Ğ³Ğ¾ÑĞ·Ğ°ĞºÑƒĞ¿Ğ¾Ğº
      Ğ¨Ğ°Ğ³ 4 â€” Ğ¡Ñ‚Ğ°Ñ‚ÑŒĞ¸ Ğ“Ğš Ğ Ğš (Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ñ‹, Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ, Ğ½ĞµÑƒÑÑ‚Ğ¾Ğ¹ĞºĞ°) â€” ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾
      Ğ¨Ğ°Ğ³ 5 â€” ĞĞ¾Ñ€Ğ¼Ñ‹ ĞĞ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ´ĞµĞºÑĞ° (ĞĞ”Ğ¡, Ğ»ÑŒĞ³Ğ¾Ñ‚Ñ‹, ÑƒÑ‡ĞµÑ‚) â€” ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾

    Args:
        question: Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ.
        conversation_history: Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°.

    Returns:
        Tuple: (Ğ¾Ñ‚Ğ²ĞµÑ‚ Claude, ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ñ‡Ğ°Ğ½ĞºĞ¾Ğ², Ğ±Ñ‹Ğ» Ğ»Ğ¸ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ ĞšĞ¢Ğ Ğ£)
    """
    # â”€â”€ Ğ¨Ğ°Ğ³ 1: ĞŸĞµÑ€ĞµÑ‡ĞµĞ½ÑŒ Ğ¢Ğ Ğ£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ktru_items = check_ktru_perechen(question)
    ktru_context = build_ktru_context(ktru_items)

    # â”€â”€ Ğ¨Ğ°Ğ³ 2: ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ñƒ Ğ¸ Ğ¸Ñ‰ĞµĞ¼ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    platform = detect_platform(question)
    platform_chunks = []
    platform_context = ""

    if platform:
        # Ğ˜Ñ‰ĞµĞ¼ ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ğ¾ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğµ (Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ½Ğ¾)
        platform_chunks = search_supabase(question, top_n=2, platform=platform)
        if platform_chunks:
            platform_label = "GOSZAKUP.GOV.KZ" if platform == "goszakup" else "OMARKET.KZ"
            platform_context = (
                f"# Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞšĞ¦Ğ˜Ğ˜ ĞŸĞ Ğ ĞĞ‘ĞĞ¢Ğ• Ğ¡ ĞŸĞĞ Ğ¢ĞĞ›ĞĞœ {platform_label}\n\n"
                + build_context(platform_chunks)
            )

    # â”€â”€ Ğ¨Ğ°Ğ³ 3: ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ Ñ‡Ğ°Ğ½ĞºĞ°Ğ¼ (Ğ·Ğ°ĞºĞ¾Ğ½, Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ•ÑĞ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´ĞºÑƒ â€” Ğ·Ğ°ĞºĞ¾Ğ½Ğ¾Ğ´Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ½Ğ¾Ñ€Ğ¼Ñ‹ Ğ¼ĞµĞ½ĞµĞµ Ğ²Ğ°Ğ¶Ğ½Ñ‹,
    # Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ¼ĞµĞ½ÑŒÑˆĞµ. Ğ•ÑĞ»Ğ¸ Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ â€” Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ğ±ÑŠÑ‘Ğ¼.
    law_top_n = 2 if platform_chunks else 3
    law_chunks = search_supabase(question, top_n=law_top_n, platform="law")

    # Ğ•ÑĞ»Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ 'law' Ğ½Ğµ Ğ´Ğ°Ğ» Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² (ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ñ‡Ğ°Ğ½ĞºĞ¸ Ğ±ĞµĞ· source_platform)
    # â€” Ğ¸Ñ‰ĞµĞ¼ Ğ±ĞµĞ· Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ° (Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ°Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ)
    if not law_chunks and not platform_chunks:
        law_chunks = search_supabase(question, top_n=3)

    # â”€â”€ Ğ¨Ğ°Ğ³ 4: ĞĞ¾Ñ€Ğ¼Ñ‹ Ğ“Ğš Ğ Ğš (ĞµÑĞ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ñ€Ğ¾ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ñ‹, Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ, etc.) â”€â”€
    civil_chunks = []
    if needs_civil_code(question):
        civil_chunks = search_supabase(question, top_n=2, platform="civil_code")

    # â”€â”€ Ğ¨Ğ°Ğ³ 5: ĞĞ¾Ñ€Ğ¼Ñ‹ ĞĞ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ´ĞµĞºÑĞ° (ĞµÑĞ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ñ€Ğ¾ ĞĞ”Ğ¡, Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸, ÑƒÑ‡ĞµÑ‚) â”€â”€â”€â”€â”€
    tax_chunks = []
    if needs_tax_code(question):
        tax_chunks = search_supabase(question, top_n=2, platform="tax")

    # â”€â”€ Ğ¨Ğ°Ğ³ 6: ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚ÑƒÑÑ‰Ğ¸Ñ… Ğ½Ğ¾Ñ€Ğ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    all_chunks = platform_chunks + law_chunks + civil_chunks + tax_chunks
    conflict_info = detect_conflicting_norms(question, all_chunks)
    conflict_chunks = []
    if conflict_info:
        conflict_chunks = conflict_info.get("conflicting_chunks", [])
        all_chunks += conflict_chunks

    if not all_chunks and not ktru_items:
        return (
            "ĞŸĞ¾ Ğ²Ğ°ÑˆĞµĞ¼Ñƒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑƒ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ¾Ğ² Ğ² Ğ±Ğ°Ğ·Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹.\n"
            "ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¸Ğ»Ğ¸ ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ñ‚Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´ĞºĞ¸.",
            0, False
        )

    # â”€â”€ Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    context_parts = []
    if ktru_context:
        context_parts.append(ktru_context)
    if platform_context:
        context_parts.append(platform_context)

    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚ÑƒÑÑ‰Ğ¸Ñ… Ğ½Ğ¾Ñ€Ğ¼Ğ°Ñ… ĞµÑĞ»Ğ¸ Ğ¾Ğ½Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹
    if conflict_info:
        conflict_explanation = (
            f"\n[WARNING] Ğ’ĞĞ–ĞĞ: ĞšĞĞĞ¤Ğ›Ğ˜ĞšĞ¢ ĞĞĞ Ğœ!\n"
            f"Ğ’ ÑÑ‚Ğ¾Ğ¼ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ¼Ğ¸ Ğ·Ğ°ĞºĞ¾Ğ½Ğ°:\n"
            f"- ĞĞ¾Ñ€Ğ¼Ñ‹ {conflict_info['positive_norms']} Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞ°ÑÑ‚ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ\n"
            f"- ĞĞ¾Ñ€Ğ¼Ñ‹ {conflict_info['conflicting_norms']} ÑÑ‚Ğ¾ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ğ°ÑÑ‚\n"
            f"ĞĞ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğµ: {conflict_info['explanation']}\n"
            f"ĞšĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚ÑƒÑÑ‰Ğ¸Ğµ Ğ½Ğ¾Ñ€Ğ¼Ñ‹ Ğ¿Ñ€Ğ¸Ğ²ĞµĞ´ĞµĞ½Ñ‹ Ğ½Ğ¸Ğ¶Ğµ.\n"
        )
        context_parts.append(conflict_explanation)

    if law_chunks:
        context_parts.append("# ĞĞĞ ĞœĞĞ¢Ğ˜Ğ’ĞĞ«Ğ• Ğ”ĞĞšĞ£ĞœĞ•ĞĞ¢Ğ«\n\n" + build_context(law_chunks))
    if conflict_chunks:
        context_parts.append("# ĞšĞĞĞ¤Ğ›Ğ˜ĞšĞ¢Ğ£Ğ®Ğ©Ğ˜Ğ• ĞĞĞ ĞœĞ«\n\n" + build_context(conflict_chunks))
    if civil_chunks:
        context_parts.append("# Ğ“Ğ ĞĞ–Ğ”ĞĞĞ¡ĞšĞ˜Ğ™ ĞšĞĞ”Ğ•ĞšĞ¡ Ğ Ğš (Ğ Ğ•Ğ›Ğ•Ğ’ĞĞĞ¢ĞĞ«Ğ• Ğ¡Ğ¢ĞĞ¢Ğ¬Ğ˜)\n\n" + build_context(civil_chunks))
    if tax_chunks:
        context_parts.append("# ĞĞĞ›ĞĞ“ĞĞ’Ğ«Ğ™ ĞšĞĞ”Ğ•ĞšĞ¡ Ğ Ğš (ĞĞĞ›ĞĞ“Ğ˜ Ğ˜ Ğ£Ğ§Ğ•Ğ¢)\n\n" + build_context(tax_chunks))

    context = "\n\n".join(context_parts)
    system = SYSTEM_PROMPT + "\n\n" + context

    messages = conversation_history + [{"role": "user", "content": question}]

    # Retry Ğ¿Ñ€Ğ¸ rate limit (Ğ´Ğ¾ 3 Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº Ñ Ğ¿Ğ°ÑƒĞ·Ğ¾Ğ¹)
    for attempt in range(3):
        try:
            response = anthropic_client.messages.create(
                model="claude-haiku-4-5-20251001",
                max_tokens=1500,
                system=[
                    {
                        "type": "text",
                        "text": system,
                        "cache_control": {"type": "ephemeral"}
                    }
                ],
                messages=messages,
            )
            answer = response.content[0].text

            # â”€â”€ Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            from hallucination_prevention import validate_answer_for_hallucinations
            validation = validate_answer_for_hallucinations(answer, all_chunks)

            # Ğ•ÑĞ»Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ - Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ
            if validation["critical_issues"]:
                warning = "\n\nâš ï¸ [Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ• - ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞĞ’]:\n"
                for issue in validation["critical_issues"]:
                    warning += f"- {issue['message']}\n"
                answer = answer + warning

            # Ğ•ÑĞ»Ğ¸ Ğ½Ğ¸Ğ·ĞºĞ°Ñ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ - Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ
            if validation["confidence"] < 0.6:
                answer += (
                    f"\n\nğŸ“ ĞŸÑ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ¾Ñ‚Ğ°: Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ {validation['confidence']:.0%}. "
                    f"Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ Ğ¸Ğ»Ğ¸ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ."
                )

            return answer, len(all_chunks), bool(ktru_items)
        except Exception as e:
            err = str(e)
            if "rate_limit" in err and attempt < 2:
                import time
                time.sleep(20)
                continue
            raise


# â”€â”€â”€ Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    print("RAG-Ğ±Ğ¾Ñ‚ Ğ¿Ğ¾ Ğ³Ğ¾ÑĞ·Ğ°ĞºÑƒĞ¿ĞºĞ°Ğ¼ Ğ Ğš (Supabase + Claude)")
    print("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ 'Ğ²Ñ‹Ñ…Ğ¾Ğ´' Ğ´Ğ»Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ\n")

    history = []
    while True:
        try:
            question = input("Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nĞ”Ğ¾ ÑĞ²Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ!")
            break
        if not question:
            continue
        if question.lower() in ("Ğ²Ñ‹Ñ…Ğ¾Ğ´", "exit", "quit"):
            break

        chunks = search_supabase(question)
        print(f"ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ‡Ğ°Ğ½ĞºĞ¾Ğ² Ğ² Supabase: {len(chunks)}")
        for c in chunks:
            title = (c.get("article_title") or c.get("chapter") or "")[:55]
            print(f"  [{c['id']}] {title}")

        print("Ğ”ÑƒĞ¼Ğ°Ñ...")
        try:
            answer, chunks_used, ktru_found = answer_question(question, history)
            print(f"\nĞÑ‚Ğ²ĞµÑ‚ (Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²={chunks_used}, ĞºÑ‚Ñ€Ñƒ={ktru_found}):\n{answer}\n")
            print("-" * 60)
            history.append({"role": "user", "content": question})
            history.append({"role": "assistant", "content": answer})
            if len(history) > 20:
                history = history[-20:]
        except Exception as e:
            import traceback
            traceback.print_exc()
